{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if /datasets/gutenberg/dataset_books_with_metadata.json exists, if so, load it\n",
    "\n",
    "# fetch the text of the books from the Gutenberg dataset (too large to upload to GitHub)\n",
    "with open(f\"./datasets/train_100M/gutenberg.train\", \"r\", encoding=\"utf-8\") as f:\n",
    "    all_books = f.read()\n",
    "lines = all_books.split(\"\\n\")\n",
    "\n",
    "# split up the books\n",
    "texts = {}\n",
    "beginning_indices = []\n",
    "for i in range(len(lines)):\n",
    "    if lines[i].startswith(\"= = = \"):\n",
    "        beginning_indices.append(i)\n",
    "\n",
    "for i in range(len(beginning_indices) - 1):\n",
    "    gutenberg_id = lines[beginning_indices[i]][8:].split()[0]\n",
    "    if not gutenberg_id.isdigit():\n",
    "        print(\"Id-length: \", len(gutenberg_id), \"for id:\", gutenberg_id)\n",
    "        continue\n",
    "    text = \" \".join(lines[(beginning_indices[i] + 1):(beginning_indices[i + 1] - 1)])\n",
    "    texts[gutenberg_id] = text\n",
    "print(f\"Found {len(texts)} books in the Gutenberg dataset.\")\n",
    "print(\"Example book text:\", texts.get(\"52018\", \"\")[:500])  # Print first 500 characters of a sample book\n",
    "\n",
    "books_with_metadata = {} # id -> { 'text': str, 'author': str, 'title': str, 'subjects': list, 'bookshelves': list }\n",
    "\n",
    "# if metadata is locally available, load it\n",
    "if os.path.exists(\"./datasets/gutenberg/dataset_books_with_metadata.json\"):\n",
    "    with open(\"./datasets/gutenberg/dataset_books_with_metadata.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "        books_with_metadata = json.load(f)\n",
    "    print(f\"Loaded {len(books_with_metadata)} books with metadata from local file.\")\n",
    "    print(\"Example book metadata:\", books_with_metadata.get(\"52018\", {}))\n",
    "\n",
    "# otherwise, fetch metadata from Gutendex\n",
    "else: \n",
    "    # Fetch metadata for each book from Gutendex\n",
    "    count = 0\n",
    "    for gutenberg_id, text in texts.items():\n",
    "        count += 1\n",
    "        if count % 50 == 0:\n",
    "            print(f\"Processing book ID {gutenberg_id}... ({count}/{len(texts)})\")\n",
    "        try:\n",
    "            response = requests.get(f\"https://gutendex.com/books/{gutenberg_id}\", timeout=30)\n",
    "            response.raise_for_status()\n",
    "            metadata = response.json()\n",
    "\n",
    "            authors = metadata.get(\"authors\", [])\n",
    "            if not authors:\n",
    "                author = \"Unknown\"\n",
    "            else:\n",
    "                author = authors[0].get(\"name\", \"Unknown\")\n",
    "            \n",
    "            books_with_metadata[gutenberg_id] = {\n",
    "                \n",
    "                'author': author,\n",
    "                'title': metadata[\"title\"],\n",
    "                'subjects': metadata[\"subjects\"],\n",
    "                'bookshelves': metadata[\"bookshelves\"]\n",
    "            }\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Failed to get metadata for book {gutenberg_id}: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing book {gutenberg_id}: {e}\")\n",
    "    with open(\"./datasets/gutenberg/dataset_books_with_metadata.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(books_with_metadata, f, ensure_ascii=False, indent=4)\n",
    "    print(len(books_with_metadata), \"books with metadata found.\")\n",
    "    print(\"Example book metadata:\", books_with_metadata.get(52018, {}))\n",
    "\n",
    "for gutenberg_id, book in books_with_metadata.items():\n",
    "    if gutenberg_id in texts:\n",
    "        book['text'] = texts[gutenberg_id]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_bookshelves = set()\n",
    "all_subjects = set()\n",
    "bookshelve_counts = {}\n",
    "bookshelve_word_counts = {}\n",
    "subject_counts = {}\n",
    "subject_word_counts = {}\n",
    "for book in books_with_metadata.values():\n",
    "    word_count = len(book[\"text\"].split())\n",
    "    for bookshelve in book[\"bookshelves\"]:\n",
    "        all_bookshelves.add(bookshelve)\n",
    "        if bookshelve in bookshelve_counts:\n",
    "            bookshelve_counts[bookshelve] += 1\n",
    "            bookshelve_word_counts[bookshelve] += word_count\n",
    "        else:\n",
    "            bookshelve_counts[bookshelve] = 1\n",
    "            bookshelve_word_counts[bookshelve] = word_count\n",
    "    for subject in book[\"subjects\"]:\n",
    "        all_subjects.add(subject)\n",
    "        if subject in subject_counts:\n",
    "            subject_counts[subject] += 1\n",
    "            subject_word_counts[subject] += word_count\n",
    "        else:\n",
    "            subject_counts[subject] = 1\n",
    "            subject_word_counts[subject] = word_count\n",
    "\n",
    "print(f\"Total unique bookshelves: {len(all_bookshelves)}\")\n",
    "print(f\"Total unique subjects: {len(all_subjects)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bookshelf_list = sorted(list(all_bookshelves))\n",
    "subject_list = sorted(list(all_subjects))\n",
    "# print 10 most common bookshelves and subjects with their counts\n",
    "print(\"\\nMost common bookshelves:\")\n",
    "sorted_bookshelves = sorted(bookshelve_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "for bookshelf, count in sorted_bookshelves[:10]:\n",
    "    print(f\"{bookshelf}: {count} books\")\n",
    "print(\"\\nMost common subjects:\")\n",
    "sorted_subjects = sorted(subject_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "for subject, count in sorted_subjects[:10]:\n",
    "    print(f\"{subject}: {count} books\")\n",
    "\n",
    "# print 10 longest bookshelves and subjects with their total word counts\n",
    "print(\"\\nLongest bookshelves:\")\n",
    "sorted_bookshelves_by_length = sorted(bookshelve_word_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "for bookshelf, word_count in sorted_bookshelves_by_length[:10]:\n",
    "    print(f\"{bookshelf}: {word_count} words\")\n",
    "print(\"\\nLongest subjects:\")\n",
    "sorted_subjects_by_length = sorted(subject_word_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "count = 1\n",
    "for subject, word_count in sorted_subjects_by_length:\n",
    "    if word_count < 500_000:\n",
    "        break\n",
    "    print(f\"{count}: {subject}: {word_count} words\")\n",
    "    count += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a mapping from subjects to books\n",
    "subject_to_book_map = {}\n",
    "for subject in all_subjects:\n",
    "    subject_to_book_map[subject] = []\n",
    "for book_id, book in books_with_metadata.items():\n",
    "    for subject in book[\"subjects\"]:\n",
    "        subject_to_book_map[subject].append(book_id)\n",
    "\n",
    "# look at all pairs of subject, and check how many books they have in common\n",
    "subject_pairs = {}\n",
    "for i in range(len(subject_list)):\n",
    "    for j in range(i + 1, len(subject_list)):\n",
    "        subject1 = subject_list[i]\n",
    "        subject2 = subject_list[j]\n",
    "        common_books = set(subject_to_book_map[subject1]) & set(subject_to_book_map[subject2])\n",
    "        if common_books:\n",
    "            subject_pairs[(subject1, subject2)] = len(common_books)\n",
    "print(\"\\nMost common subject pairs:\")\n",
    "sorted_subject_pairs = sorted(subject_pairs.items(), key=lambda x: x[1], reverse=True)\n",
    "for (subject1, subject2), count in sorted_subject_pairs[:10]:\n",
    "    print(f\"{subject1} & {subject2}: {count} common books\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes in a list of tuples (gutenberg_id, name) a filename and a word limit\n",
    "# writes file with the books that have a word count less than the limit to \n",
    "# ./datasets/gutenberg/genres/filename.train\n",
    "def create_dataset_from_list(books, filename, word_limit):\n",
    "    if os.path.exists(f\"./datasets/gutenberg/genres/{filename}.train\"):\n",
    "        os.remove(f\"./datasets/gutenberg/genres/{filename}.train\")\n",
    "    word_count = 0\n",
    "    for gutenberg_id, name in books:\n",
    "        try:\n",
    "            response = requests.get(f\"https://www.gutenberg.org/cache/epub/{gutenberg_id}/pg{gutenberg_id}.txt\", timeout=30)\n",
    "            response.raise_for_status()\n",
    "            text = response.text\n",
    "            print(f\"Processing book {gutenberg_id} - {name}... ({len(text.split())} words)\")\n",
    "            # print(f\"First 100 characters: {text[:100]}\")\n",
    "            if word_count + len(text.split()) > word_limit:\n",
    "                print(f\"Word limit reached. Stopping.\")\n",
    "                # write the remaining number of words to hit the word limit exactly\n",
    "                text = \" \".join(text.split()[:word_limit - word_count])\n",
    "                with open(f\"./datasets/gutenberg/genres/{filename}.train\", \"a\", encoding=\"utf-8\") as f:\n",
    "                    f.write(f\"= = = {gutenberg_id} {name}\\n\")\n",
    "                    f.write(text + \"\\n\")\n",
    "                print(f\"Wrote {word_count + len(text.split())} words to {filename}.train with word limit {word_limit}.\")\n",
    "                break\n",
    "            word_count += len(text.split())\n",
    "            with open(f\"./datasets/gutenberg/genres/{filename}.train\", \"a\", encoding=\"utf-8\") as f:\n",
    "                f.write(f\"= = = {gutenberg_id} {name}\\n\")\n",
    "                f.write(text + \"\\n\")\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Failed to get book {gutenberg_id}: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing book {gutenberg_id}: {e}\")\n",
    "    print(f\"Total words written to {filename}.train: {word_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing book 55 - The Wonderful Wizard of Oz... (42687 words)\n",
      "First 500 characters: ﻿The Project Gutenberg eBook of The Wonderful Wizard of Oz\n",
      "    \n",
      "This ebook is for the use of anyon\n",
      "Processing book 36 - The War of the Worlds... (63114 words)\n",
      "First 500 characters: ﻿The Project Gutenberg eBook of The War of the Worlds\n",
      "    \n",
      "This ebook is for the use of anyone any\n",
      "Failed to get book 20000: 404 Client Error: Not Found for url: https://www.gutenberg.org/cache/epub/20000/pg20000.txt\n",
      "Processing book 7477 - The Book of Wonder... (25906 words)\n",
      "First 500 characters: ﻿The Project Gutenberg eBook of The Book of Wonder\n",
      "    \n",
      "This ebook is for the use of anyone anywhe\n",
      "Processing book 20782 - Triplanetary... (60200 words)\n",
      "First 500 characters: ﻿The Project Gutenberg eBook of Triplanetary\n",
      "    \n",
      "This ebook is for the use of anyone anywhere in \n",
      "Processing book 10002 - The House on the Borderland... (53976 words)\n",
      "First 500 characters: ﻿The Project Gutenberg eBook of The House on the Borderland\n",
      "    \n",
      "This ebook is for the use of anyo\n",
      "Processing book 35 - The Time Machine... (35483 words)\n",
      "First 500 characters: ﻿The Project Gutenberg eBook of The Time Machine\n",
      "    \n",
      "This ebook is for the use of anyone anywhere\n",
      "Processing book 18857 - A Journey to the Centre of the Earth... (88879 words)\n",
      "First 500 characters: ﻿The Project Gutenberg eBook of A Journey to the Centre of the Earth\n",
      "    \n",
      "This ebook is for the us\n",
      "Processing book 1250 - Anthem... (22183 words)\n",
      "First 500 characters: ﻿The Project Gutenberg eBook of Anthem\n",
      "    \n",
      "This ebook is for the use of anyone anywhere in the Un\n",
      "Processing book 159 - The Island of Doctor Moreau... (46589 words)\n",
      "First 500 characters: ﻿The Project Gutenberg eBook of The island of Doctor Moreau\n",
      "    \n",
      "This ebook is for the use of anyo\n",
      "Processing book 21279 - 2 B R 0 2 B... (5661 words)\n",
      "First 500 characters: ﻿The Project Gutenberg eBook of 2 B R 0 2 B\n",
      "    \n",
      "This ebook is for the use of anyone anywhere in t\n",
      "Processing book 8395 - The Gods of Pegāna... (18768 words)\n",
      "First 500 characters: ﻿The Project Gutenberg eBook of The Gods of Pegana\n",
      "    \n",
      "This ebook is for the use of anyone anywhe\n",
      "Processing book 11 - Alice's Adventures in Wonderland... (29564 words)\n",
      "First 500 characters: ﻿The Project Gutenberg eBook of Alice's Adventures in Wonderland\n",
      "    \n",
      "This ebook is for the use of\n",
      "Processing book 7506 - The Steam Man of the Prairies... (32738 words)\n",
      "First 500 characters: ﻿The Project Gutenberg eBook of The Huge Hunter; Or, The Steam Man of the Prairies\n",
      "    \n",
      "This ebook\n",
      "Processing book 289 - The Night Land... (61469 words)\n",
      "First 500 characters: ﻿The Project Gutenberg eBook of The Wind in the Willows\n",
      "    \n",
      "This ebook is for the use of anyone a\n",
      "Processing book 1230 - The Lost World... (10907 words)\n",
      "First 500 characters: ﻿The Project Gutenberg eBook of Pierre Grassou\n",
      "    \n",
      "This ebook is for the use of anyone anywhere i\n",
      "Processing book 22615 - The Princess Nobody: A Tale of Fairyland... (4851 words)\n",
      "First 500 characters: ﻿The Project Gutenberg eBook of A Scena do Odio\n",
      "    \n",
      "This ebook is for the use of anyone anywhere \n",
      "Processing book 1505 - The First Men in the Moon... (18077 words)\n",
      "First 500 characters: ﻿The Project Gutenberg eBook of The Rape of Lucrece\n",
      "    \n",
      "This ebook is for the use of anyone anywh\n",
      "Processing book 12163 - The Sleeper Awakes... (78780 words)\n",
      "First 500 characters: ﻿The Project Gutenberg eBook of The Sleeper Awakes\n",
      "    \n",
      "This ebook is for the use of anyone anywhe\n",
      "Processing book 3479 - The Metal Monster... (84382 words)\n",
      "First 500 characters: ﻿The Project Gutenberg eBook of The Metal Monster\n",
      "    \n",
      "This ebook is for the use of anyone anywher\n",
      "Processing book 17355 - The Runaway Skyscraper... (19171 words)\n",
      "First 500 characters: ﻿The Project Gutenberg eBook of The Runaway Skyscraper\n",
      "    \n",
      "This ebook is for the use of anyone an\n",
      "Processing book 829 - Gulliver's Travels... (108135 words)\n",
      "First 500 characters: ﻿The Project Gutenberg eBook of Gulliver's Travels into Several Remote Nations of the World\n",
      "    \n",
      "T\n",
      "Processing book 12 - Through the Looking‑Glass... (32784 words)\n",
      "First 500 characters: ﻿The Project Gutenberg eBook of Through the Looking-Glass\n",
      "    \n",
      "This ebook is for the use of anyone\n",
      "Processing book 780 - The War in the Air... (100160 words)\n",
      "First 500 characters: ﻿The Project Gutenberg eBook of The War in the Air\n",
      "    \n",
      "This ebook is for the use of anyone anywhe\n",
      "Word limit reached. Stopping.\n",
      "Wrote 1000000 words to 1M_sci-fi_fantasy.train with word limit 1000000.\n",
      "Total words written to 1M_sci-fi_fantasy.train: 944304\n"
     ]
    }
   ],
   "source": [
    "sci_fi_fantasy = [\n",
    "    (55, \"The Wonderful Wizard of Oz\"),\n",
    "    (36, \"The War of the Worlds\"),\n",
    "    (20000, \"Twenty Thousand Leagues Under the Sea\"),\n",
    "    (7477, \"The Book of Wonder\"),\n",
    "    (20782, \"Triplanetary\"),\n",
    "    (10002, \"The House on the Borderland\"),\n",
    "    (35, \"The Time Machine\"),\n",
    "    (18857, \"A Journey to the Centre of the Earth\"),\n",
    "    (1250, \"Anthem\"),\n",
    "    (159, \"The Island of Doctor Moreau\"),\n",
    "    (21279, \"2 B R 0 2 B\"),\n",
    "    (8395, \"The Gods of Pegāna\"),\n",
    "    (11, \"Alice's Adventures in Wonderland\"),   \n",
    "    (7506, \"The Steam Man of the Prairies\"),              \n",
    "    (289, \"The Night Land\"),                              \n",
    "    (1230, \"The Lost World\"),                            \n",
    "    (22615, \"The Princess Nobody: A Tale of Fairyland\"),  \n",
    "    (1505, \"The First Men in the Moon\"),                \n",
    "    (12163, \"The Sleeper Awakes\"),                      \n",
    "    (3479, \"The Metal Monster\"),                       \n",
    "    (17355, \"The Runaway Skyscraper\"),                  \n",
    "    (829, \"Gulliver's Travels\"),\n",
    "    (12, \"Through the Looking‑Glass\"),\n",
    "    (780, \"The War in the Air\"),           \n",
    "    (765, \"The Moon Pool\"),               \n",
    "    (1013, \"The First Men in the Moon\"),   \n",
    "]\n",
    "\n",
    "create_dataset_from_list(sci_fi_fantasy, \"1M_sci-fi_fantasy\", 1_000_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
